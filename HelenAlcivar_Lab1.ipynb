{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9447350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe364f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importacion de las librerias que seran módulos necesarios para el desarrollo el algoritmo de SVM en el desarrollo del laboratorio \n"
     ]
    }
   ],
   "source": [
    "def importlibrerias():\n",
    "\n",
    "    '''Importacion de las librerias que seran módulos necesarios para el desarrollo el algoritmo de SVM en el desarrollo del laboratorio '''\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from  sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "print(importlibrerias.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522b53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargar y leer el conjunto de datos de plantas de iris mediate la librería scikit-learn\n"
     ]
    }
   ],
   "source": [
    "def carga():\n",
    "    \n",
    "    '''Cargar y leer el conjunto de datos de plantas de iris mediate la librería scikit-learn'''\n",
    "dicc = datasets.load_iris()\n",
    "print(carga.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8fd4cfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10084/3325138010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m'''Visualizacion del diccionario  de datos'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdicc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dicc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "'''Visualizacion del diccionario  de datos'''\n",
    "dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Visualizacion de las colunmas del Dataframe'''\n",
    "dicc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032afb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defCaracteristicas():\n",
    "    \n",
    "    '''Visualizacion del nombre de las características (X), para la verificación de datos.'''\n",
    "print(\"Feactures: \\n\" , dicc.feature_names)\n",
    "print(defCaracteristicas.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1b88828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defObjetivo():\n",
    "    \n",
    "    '''Visualizacion de los nombres de las  etiquetas '''\n",
    "print(\"Labels: \\n\" , dicc.target_names)\n",
    "print(defObjetivo.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "576b7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarvalores():\n",
    "    \n",
    "    '''Visualizacion de las filas y colunmas correspondientes'''\n",
    "print(\"Shape: \\n\" , dicc.data.shape)\n",
    "print(mostrarvalores.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc922611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mostrarvaloresf():\n",
    "\n",
    "    '''Visualizacion del resultado de nuestras etiquetas, mismo que tenemos 3 que son: 0,1,2'''\n",
    "print(\"target: \\n\" , dicc.target)\n",
    "print(mostrarvaloresf.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b5a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeclaraciondeV():\n",
    "\n",
    "    '''Declaracion de las variables X y y'''\n",
    "X = dicc.data\n",
    "y = dicc.target\n",
    "print(DeclaraciondeV.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3d9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entrenar():\n",
    "\n",
    "    '''Crecion de la funcion para entrenar el modelo tomando el 70 porciento de datos del dataset y el 30 para las pruebas del azar'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=109)\n",
    "print(Entrenar.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f36d09f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_10084/4008479433.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Equipo\\AppData\\Local\\Temp/ipykernel_10084/4008479433.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    '''Imprimir la funcion declarada optando con las metricas del 70 porciento de datos del dataset y el 30 para las pruebas del azar '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def Imprimir():\n",
    "    \n",
    "    '''Imprimir la funcion declarada optando con las metricas del 70 porciento de datos del dataset y el 30 para las pruebas del azar '''\n",
    " print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(Imprimir.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deb0d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearMK():\n",
    "    \n",
    "    '''Creacion del modelo kernerl el lineal'''\n",
    "clf = svm.SVC(kernel='linear')\n",
    "print(crearMC.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28a26989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EntrenarM():\n",
    "    \n",
    "    '''Entrenamiento del modelo'''\n",
    "clf.fit(X_train, y_train)\n",
    "print(EntrenarM.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerdicciM():\n",
    "    \n",
    "    '''Realizacion de la prediccion del modelo'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(PerdicciM.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf31ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImprimesionM():\n",
    "    \n",
    "    '''Impresion  de la prediccion del modelo'''\n",
    "print(y_pred)\n",
    "print(ImprimesionM.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluacionM():\n",
    "\n",
    "    '''Evaluacion del modelo  mediante las metricas, primer modelo a evaluar Accurry'''\n",
    "\n",
    "print(\"Accury:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(EvaluacionM.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ff773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluacionP():\n",
    "    \n",
    "    '''Evaluacion del modelo  mediante las metricas, segundo modelo a evaluar Precision'''\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(EvaluacionP.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ab0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " def EvaluacionR():   \n",
    "   \n",
    "    '''Evaluacion del modelo  mediante las metricas, segundo modelo a evaluar Recall'''\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "print(EvaluacionP.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dfcf69",
   "metadata": {},
   "outputs": [],
   "source": [
    " def Matriz(): \n",
    "   \n",
    "    '''actuales del dataset y los predichos del modelo'''\n",
    "data = {'y_Actual':    y_test,\n",
    "        'y_Predicted': y_pred\n",
    "            }\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    sn.heatmap(confusion_matrix, annot=True)\n",
    "    plt.show()\n",
    "    print(Matriz.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680fba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
